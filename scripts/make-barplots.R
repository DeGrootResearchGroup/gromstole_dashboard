## based on omicron-retro.R, priority analysis of BA1/BA2/B.1.1.529

#setwd('~/git/gromstole')

args <- commandArgs(trailingOnly = TRUE)
if (length(args) < 2) {
  stop("Usage: Rscript make-barplots.R [input dir] [lineage CSV] ",
       "[outfile] (metadata)\n",
       "  input dir:  run folder of CSV files generated by minimap2.py\n",
       "  lineage CSV:  path to CSV with mutation list for lineage\n",
       "  output path:  path to write PDF file\n",
       "  metadata:  optional, path to metadata CSV file")
}
run.dir <- args[1]  # location of CSV outputs from minimap2.py
lineage.file <- args[2]  # must include type, pos, alt, label
outfile <- args[3]
metafile <- NA
if (length(args) > 3) {
  metafile <- args[4]
}

lineage <- gsub("\\.csv$", "", basename(lineage.file))
mutlist <- read.csv(lineage.file)
mutlist$key <- paste(mutlist$type, mutlist$pos, mutlist$alt, sep="|")


# locate data files
require(here)
mfiles <- list.files(here(run.dir), full.names = TRUE,
                     pattern=".+\\.mapped\\.csv$")
mfiles <- mfiles[!grepl("Undetermined", basename(mfiles))]
cfiles <- list.files(here(run.dir), full.names = TRUE,
                     pattern=".+\\.coverage\\.csv$")  
cfiles <- cfiles[!grepl("Undetermined", basename(cfiles))]

if(length(mfiles) == 0) 
  stop("No *.mapped.csv files found!")
if(length(cfiles) == 0) 
  stop("No *.coverage.csv files found!")
if(length(mfiles) != length(cfiles)) 
  stop("Mismatch between number of *.mapped.csv and *.coverage.csv files")


# import coverage data
cover <- sapply(cfiles, function(f) {
  coverage <- read.csv(f, stringsAsFactors = FALSE)
  # NOTE: coverage$position is 0-index, mutlist$pos is 1-index
  idx <- match(mutlist$pos, coverage$position+1)
  coverage$coverage[idx[!is.na(idx)]]
})
row.names(cover) <- mutlist$label
cover <- as.data.frame(cover)
names(cover) <- sapply(strsplit(colnames(cover), split = "/"), function(x) {
  strsplit(x[length(x)], split = "\\.")[[1]][1]
})


# import mutation frequency data
maps <- sapply(mfiles, function(f) {
  mapped <- read.csv(f, stringsAsFactors = FALSE)
  mapped$type <- substr(mapped$label, 1, 1)
  mapped$pos <- mapped$position+1
  mapped$alt <- sapply(strsplit(mapped$label, as.character(mapped$pos)), 
                       function(x) {
                         gsub("^\\.", "", x[2])
                       })
  # convert to omicron label type
  mapped$key <- paste(mapped$type, mapped$pos, mapped$alt, sep='|')
  
  index <- match(mutlist$key, mapped$key)
  mapped$frequency[index]
})
row.names(maps) <- mutlist$label
maps <- as.data.frame(maps)

# set column names to sample identifiers
names(maps) <- sapply(strsplit(colnames(maps), split = "/"), function(x) {
  strsplit(x[length(x)], split = "\\.")[[1]][1]
})


# set zeroes for sites with non-zero coverage
# FIXME: this is not very elegant
mask <- (cover > 0)
for (i in 1:nrow(maps)) {
  for (j in 1:ncol(maps)) {
    if (is.na(maps[i,j]) & mask[i,j]) { maps[i,j] <- 0 }
  }
}

# convert to integer counts
counts <- as.data.frame(t(maps*cover))
row.names(counts) <- NULL
names(counts) <- mutlist$label
counts$sample <- names(maps)
# switching to `here` library broke this line
counts$lab <- sapply(cfiles, function(x) {
  tokens <- strsplit(x, "/")[[1]]
  tokens[length(tokens)-2]
})


# parse metadata, dealing with varying header labels and date formats
require(lubridate)
counts$coldate <- rep(NA, times=nrow(counts))
counts$site <- rep(NA, times=nrow(counts))

if (!is.na(metafile)) {
  meta <- read.csv(metafile)
  #idx <- match(counts$sample, meta[,which(grepl("sample\\.ID", names(meta)))])
  r1.fn <- meta[,which(grepl("[Rr]1\\.fastq\\.filename", names(meta)))]
  idx <- match(counts$sample, sapply(r1.fn, function(x) {
    strsplit(as.character(x), "_")[[1]][1]
    }))
  
  # parse sample collection dates
  date.col <- which(grepl("collection\\.date", names(meta)))
  if (is.na(date.col)) {
    warning("Failed to locate sample collection date column.")
  } else {
    date.str <- meta[idx, date.col]
    counts$coldate <- as.Date(parse_date_time(date.str, c("mdy", "dmy", "ymd")))
  }
  
  # parse sampling location
  loc.col <- which(grepl("location.name", names(meta)))
  if (is.na(loc.col)) {
    warning("Failed to locate sampling location in metadata")
  } else {
    counts$site <- substr(meta[idx, loc.col], 1, 10)
  }
}

cvr <- as.data.frame(t(cover))
names(cvr) <- names(counts)[1:ncol(cvr)]


# sort by site and collection date
idx <- order(counts$site, counts$coldate, counts$sample, decreasing=T)
counts <- counts[idx, ]
cvr <- cvr[idx, ]
if (all(is.na(counts$site))) {
  names.arg <- counts$sample
} else {
  names.arg <- paste(counts$site, format(counts$coldate, "%b %d"), 
                     counts$sample)  
}


est.freq <- function() {
  probs <- c()
  lo <- c()
  hi <- c()
  for (i in 1:nrow(counts)) {
    y <- as.integer(counts[i, 1:ncol(cvr)])  # number of "successes"
    n <- as.integer(cvr[i, ])  # number of trials
    # Avoid bars that will have huge error bars
    if(sum(y, na.rm = TRUE) < 3 | max(n[y > 0], na.rm = TRUE) < 15) {
      probs <- c(probs, NA)
      lo <- c(lo, NA)
      hi <- c(hi, NA)
      next
    }
    p <- tryCatch({
      fit <- glm(cbind(y, n-y) ~ 1, family='binomial')
      exp(fit$coef) / (1+exp(fit$coef))  # probability
    }, 
    error = function(cond) { 
      return (NA) 
    })
    probs <- c(probs, p)
    if (is.na(p) | p < 1e-5) { # p<1e-5 means confidence intervals fail
      lo <- c(lo, NA)
      hi <- c(hi, NA)
    } else {
      suppressMessages(ci <- tryCatch(confint(fit)))
      lo <- c(lo, exp(ci[1]) / (1+exp(ci[1])))
      hi <- c(hi, exp(ci[2]) / (1+exp(ci[2])))
    }
  }
  return (list(probs=probs, lo=lo, hi=hi))
}


#' Note: I had separated this code into a function when generating 
#' multiple barplots for the same run
draw.barplot <- function(main, names.arg) {
  res <- est.freq()
  n.muts <- apply(cvr, 1, function(x) sum(x>0, na.rm=T))
  pal <- colorRampPalette(c("white", "steelblue"))(ncol(cvr))
  
  par(mar=c(5,8,2,8), mfrow=c(1,1), cex=1)
  mp <- barplot(as.numeric(res$probs), horiz=T, main=NA, cex.main=1.3, 
          names.arg=names.arg,
          las=1, cex.names=0.6, xlim=c(0, 1),  #max(res$hi, na.rm=T)),
          xlab="Estimated frequency", cex.lab=1.2,
          col=pal[n.muts], 
          border=ifelse(res$lo > 0.01, "black", "grey60")
          )
          #col=ifelse(res$lo > 0.01, 'salmon', 'grey'))
  title(main=paste(" ", main), font.main=1, cex.main=1.6, 
        adj=0, outer=TRUE, line=-1.5)
  segments(x0=res$lo, x1=res$hi, y0=mp, 
           lwd=2, col=ifelse(res$lo > 0.01, "black", "grey60"))
  abline(v=0.01, lty=2)
  
  u <- par('usr')  # user coordinates of plot region (x1, x2, y1, y2)
  
  # add heatmap
  dy <- unique(diff(mp))
  par(xpd=NA)
  for (i in 1:nrow(cvr)) {
    for (j in 1:ncol(cvr)) {
      rect(xleft=1.05+0.3*(j-1)/ncol(cvr), xright=1.05+0.3*j/ncol(cvr),
           ybottom=dy*(i-1), ytop=dy*(i), 
           #col=ifelse(cvr[i,j] > 0, ifelse(cvr[i,j] > 100, 'steelblue', "lightgrey"), 'white'),
           col=c("white", "grey", "steelblue1", "steelblue4")[cut(cvr[i,j], breaks = c(-Inf,0,10,100,Inf))],
           border='white', lwd=0.5)
    }
  }
  text(x=dy, y=dy*(nrow(cvr)+1), adj=0.5, label="Coverage\nGrey>0, blue>10, dark>100", cex=0.8)
  #text(x=u[1], y=u[3], adj=0, label=run.dir, cex=0.5)
  title(xlab=paste(" ", run.dir), outer=TRUE, adj=0, cex.lab=0.5, 
        font=1, line=-1)
  par(xpd=FALSE)
  abline(h = 0:ncol(cvr)*dy[1]+0.1, col = "gray88", lty = 2)
}


pdf(file=outfile, width=7, height=max(5, nrow(counts)/5))
draw.barplot(main=lineage, names.arg=names.arg)
dev.off()

