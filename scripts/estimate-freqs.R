#' The purpose of this script is to fit a (quasi)binomial model to 
#' the observed frequencies of mutations that are previously determined
#' to be characteristic of a specific lineage of SARS-CoV-2.  It is meant 
#' to be run on a set of CSV outputs generated by minimap2.py

# parse command line arguments
args <- commandArgs(trailingOnly = TRUE)
if (length(args) < 3) {
  stop("\n\nUsage: Rscript estfreq.R [input dir] [lineage CSV] ",
       "[output JSON] (metadata)\n",
       "  input dir:  run folder of CSV files generated by minimap2.py\n",
       "  constellation JSON:  path to JSON with constellation\n",
       "  output JSON:  path to write JSON of frequency estimates\n",
       "  metadata:  optional, path to metadata CSV file\n\n")
}
run.dir <- args[1]  # location of CSV outputs from minimap2.py
stelfile <- args[2]
outfile <- args[3]
metafile <- NA
if (length(args) > 3) {
  metafile <- args[4]
}


#' re.findall
#'
#' Emulate behaviour of Python's re.findall() function
#'
#' @param pat:  regex pattern
#' @param s:  character, a single string
#' @return character, vector of all matching substrings
re.findall <- function(pat, s) {
  if (!is.character(s)) {
    stop("re.findall() requires a character object for input 's'")
  }
  matches <- gregexpr(pat, s)
  index <- as.integer(matches[[1]])
  match.length <- attr(matches[[1]], 'match.length')
  
  sapply(1:length(index), function(i) {
    start <- index[i]
    stop <- start + match.length[i] - 1
    substr(s, start, stop)
  })
}


orfs <- list(
  'orf1a'= c(265, 13468),
  'orf1b'= c(13467, 21555),
  'S'= c(21562, 25384),
  'orf3a'= c(25392, 26220),
  'E'= c(26244, 26472),
  'M'= c(26522, 27191),
  'orf6'= c(27201, 27387),
  'orf7a'= c(27393, 27759),
  'orf7b'= c(27755, 27887),
  'orf8'= c(27893, 28259),
  'N'= c(28273, 29533),
  'orf10'= c(29557, 29674)
)


require(lubridate)
require(jsonlite)

# load the lineage definition (mutation list)
lineage <- gsub("^c|\\.json$", "", basename(stelfile))
constellation <- jsonlite::read_json(stelfile, simplifyVector = TRUE)

# Calculate the length of orf1a to determine if a mutation is in orf1a or orf1b
len_1a <- (orfs[['orf1a']][2]-orfs[['orf1a']][1])/3 + 1

# convert constellation to label notation in the mapped files
sites <- lapply(constellation$sites, function(d) {
  toks <- toupper(strsplit(d, ":")[[1]])

  if (toks[1] != "DEL" && toks[1] != "NUC")
    toks <- c("aa", toks)
  
  if (toks[2] == "S" || toks[2] == "SPIKE") {
    toks[[2]] <- "S"
  } else if (toks[1] == "DEL") {
    toks[[1]] <- "del"
  } else if (toks[1] == "NUC") {
    toks <- toks[-1]
  } else if (toks[2] == "ORF1AB" || toks[2] == "1AB") {
    num <- as.numeric(re.findall("\\d+", toks[3]))
    if (num <= len_1a) {
      toks[[2]] <- "orf1a"
    } else {
      # Determine nucleotide position relative to the start of orf1b
      new_pos <- (((num-1) * 3 + orfs[['orf1a']][1]) - orfs[['orf1b']][1])/3
      toks[[3]] <- gsub(num, floor(new_pos) + 1, toks[[3]])
      toks[[2]] <- "orf1b"
    }
  } else if (nchar(toks[2]) >= 3 && substring(toks[2], 1, 3) == "ORF") {
    toks[[2]] <- tolower(toks[2])
  }
  
  if (grepl("+", toks[1], fixed = TRUE)) {
    ins <- strsplit(toks[[1]], split = "[+]")[[1]]
    toks[[1]] <- gsub(" ", "", paste("+", ins[1], ".", ins[2]))
  }
  toks <- paste(toks, collapse = ":")
})

sites <- unlist(sites, recursive = FALSE)

# Initialize list for constellation$site positions
pos <- rep(NA, length(sites))
names(pos) <- sites

# locate data files
require(here)
mfiles <- list.files(here(run.dir), full.names = TRUE,
                     pattern=".+\\.mapped\\.csv$")
mfiles <- mfiles[!grepl("Undetermined", basename(mfiles))]
cfiles <- list.files(here(run.dir), full.names = TRUE,
                     pattern=".+\\.coverage\\.csv$")  
cfiles <- cfiles[!grepl("Undetermined", basename(cfiles))]

if(length(mfiles) == 0) 
  stop("No *.mapped.csv files found!")
if(length(cfiles) == 0) 
  stop("No *.coverage.csv files found!")
if(length(mfiles) != length(cfiles)) 
  stop("Mismatch between number of *.mapped.csv and *.coverage.csv files")


# import mutation frequency data
maps <- sapply(mfiles, function(f) {
  mapped <- read.csv(f, stringsAsFactors = FALSE)
  mapped$type <- substr(mapped$label, 1, 1)
  mapped$pos <- mapped$position+1
  mapped$alt <- sapply(strsplit(mapped$label, as.character(mapped$pos)), 
                       function(x) {
                         gsub("^\\.", "", x[2])
                       })
  
  mapped$label <- gsub("^~", "", mapped$label)
   
  index_label <- match(sites, mapped$label)
  index <- match(sites, mapped$mutation)
  
  for (i in 1:length(index)) {
    if (!is.na(index_label[i])) {
      index[[i]] <- index_label[[i]]
    }
    if (!is.na(index[[i]]) && is.na(pos[[i]])) {
      pos[[i]] <<- mapped$pos[[index[[i]]]]
    }
  }
  mapped$frequency[index]
})
row.names(maps) <- constellation$sites
maps <- as.data.frame(maps)

# set column names to sample identifiers
names(maps) <- sapply(strsplit(colnames(maps), split = "/"), function(x) {
  strsplit(x[length(x)], split = "\\.")[[1]][1]
})

# Assign position values if the site doesn't appear in the mapped files
for (i in 1:length(pos)) {
  if (is.na(pos[[i]])) {
    toks <- strsplit(sites[i], ":")[[1]]
    if (length(toks) == 1) {
      num <- re.findall("\\d+", toks[1])
      pos[[i]] <- num
    } else if (toks[1] == "del") {
      pos[[i]] <- toks[2]
    }
    else {
      #TODO: Error handling
      start_pos <- orfs[[toks[2]]][1]
      codon <- as.numeric(re.findall("\\d+", toks[3]))
      pos[[i]] <- start_pos + (codon - 1) * 3
    }
  }
}


# import coverage data
cvr <- sapply(cfiles, function(f) {
  coverage <- read.csv(f, stringsAsFactors = FALSE)
  # NOTE: coverage$position is 0-index, pos is 1-index
  idx <- match(pos, coverage$position+1)
  coverage$coverage[idx[!is.na(idx)]]
})
row.names(cvr) <- constellation$sites
cvr <- as.data.frame(cvr)
names(cvr) <- sapply(strsplit(colnames(cvr), split = "/"), function(x) {
  strsplit(x[length(x)], split = "\\.")[[1]][1]
})


# set zeroes for sites with non-zero coverage
# FIXME: this is not very elegant
mask <- (cvr > 0)
for (i in 1:nrow(maps)) {
  for (j in 1:ncol(maps)) {
    if (is.na(maps[i,j]) & mask[i,j]) { maps[i,j] <- 0 }
  }
}

# convert to integer counts
counts <- as.data.frame(t(maps*cvr))
row.names(counts) <- NULL
names(counts) <- constellation$sites
row.names(counts) <- names(maps)

cvr <- as.data.frame(t(cvr))
names(cvr) <- constellation$sites

# parse metadata, dealing with varying header labels and date formats
metadata <- data.frame(sample=names(maps))
metadata$lab <- sapply(cfiles, function(x) {
  tokens <- strsplit(x, "/")[[1]]
  tokens[length(tokens)-2]
})
metadata$coldate <- rep(NA, times=nrow(counts))
metadata$site <- rep(NA, times=nrow(counts))

if (!is.na(metafile)) {
  meta <- read.csv(metafile)
  #idx <- match(counts$sample, meta[,which(grepl("sample\\.ID", names(meta)))])
  r1.fn <- meta[,which(grepl("[Rr]1\\.fastq\\.filename", names(meta)))]
  idx <- match(metadata$sample, sapply(r1.fn, function(x) {
    strsplit(as.character(x), "_")[[1]][1]
  }))
  
  # parse sample collection dates
  date.col <- which(grepl("collection\\.date", names(meta)))
  if (is.na(date.col)) {
    warning("Failed to locate sample collection date column.")
  } else {
    date.str <- meta[idx, date.col]
    metadata$coldate <- as.Date(parse_date_time(date.str, c("mdy", "dmy", "ymd")))
  }
  
  # parse sampling location
  loc.col <- which(grepl("location.name", names(meta)))
  if (is.na(loc.col)) {
    warning("Failed to locate sampling location in metadata")
  } else {
    metadata$site <- meta[idx, loc.col]
  }
}


# sort by site and collection date
idx <- order(metadata$site, metadata$coldate, metadata$sample, decreasing=T)
metadata <- metadata[idx, ]
counts <- counts[idx, ]
cvr <- cvr[idx, ]


# estimate variant frequencies
probs <- rep(NA, nrow(counts))
lo <- rep(NA, nrow(counts))
hi <- rep(NA, nrow(counts))
for (i in 1:nrow(counts)) {
  y <- as.integer(counts[i, 1:ncol(cvr)])  # number of "successes"
  n <- as.integer(cvr[i, ])  # number of trials
  # Avoid bars that will have huge error bars
  if(sum(y, na.rm = TRUE) < 3) {
    next
  }
  probs[i] <- tryCatch({
    fit <- glm(cbind(y, n-y) ~ 1, family='quasibinomial')
    exp(fit$coef) / (1+exp(fit$coef))  # probability
    }, 
    error = function(cond) { return (NA) }
    )
  
  if (sum(is.na(y)) < length(y)-1 & !is.na(probs[i]) & probs[i] >= 1e-5) { # p<1e-5 means confidence intervals fail
    suppressMessages(ci <- tryCatch(confint(fit)))
    lo[i] <- exp(ci[1]) / (1+exp(ci[1]))
    hi[i] <- exp(ci[2]) / (1+exp(ci[2]))
  }
}
estimate <- data.frame(est=probs, lower.95=lo, upper.95=hi)
row.names(estimate) <- row.names(counts)

# write output JSON
output <- list(counts=counts, coverage=cvr, metadata=metadata,
               estimate=estimate, lineage=lineage, run.dir=run.dir)
jsonlite::write_json(output, outfile, pretty=TRUE)

