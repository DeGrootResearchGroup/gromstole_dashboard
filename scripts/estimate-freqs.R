#' The purpose of this script is to fit a (quasi)binomial model to 
#' the observed frequencies of mutations that are previously determined
#' to be characteristic of a specific lineage of SARS-CoV-2.  It is meant 
#' to be run on a set of CSV outputs generated by minimap2.py

# parse command line arguments
args <- commandArgs(trailingOnly = TRUE)
if (length(args) < 3) {
  stop("\n\nUsage: Rscript estfreq.R [input dir] [lineage CSV] ",
       "[output JSON] (metadata)\n",
       "  input dir:  run folder of CSV files generated by minimap2.py\n",
       "  constellation JSON:  path to JSON with constellation\n",
       "  output JSON:  path to write JSON of frequency estimates\n",
       "  metadata:  optional, path to metadata CSV file\n\n")
}
run.dir <- args[1]  # location of CSV outputs from minimap2.py
stelfile <- args[2]
outfile <- args[3]
metafile <- NA
if (length(args) > 3) {
  metafile <- args[4]
}

require(lubridate)
require(jsonlite)

# load the lineage definition (mutation list)
lineage <- gsub("^c|\\.json$", "", basename(stelfile))
constellation <- read_json(stelfile, simplifyVector = T)


# locate data files
require(here)
mfiles <- list.files(here(run.dir), full.names = TRUE,
                     pattern=".+\\.mapped\\.csv$")
mfiles <- mfiles[!grepl("Undetermined", basename(mfiles))]
cfiles <- list.files(here(run.dir), full.names = TRUE,
                     pattern=".+\\.coverage\\.csv$")  
cfiles <- cfiles[!grepl("Undetermined", basename(cfiles))]

if(length(mfiles) == 0) 
  stop("No *.mapped.csv files found!")
if(length(cfiles) == 0) 
  stop("No *.coverage.csv files found!")
if(length(mfiles) != length(cfiles)) 
  stop("Mismatch between number of *.mapped.csv and *.coverage.csv files")


# import coverage data
cvr <- sapply(cfiles, function(f) {
  coverage <- read.csv(f, stringsAsFactors = FALSE)
  # NOTE: coverage$position is 0-index, mutlist$pos is 1-index
  idx <- match(mutlist$pos, coverage$position+1)
  coverage$coverage[idx[!is.na(idx)]]
})
row.names(cvr) <- mutlist$label
cvr <- as.data.frame(cvr)
names(cvr) <- sapply(strsplit(colnames(cvr), split = "/"), function(x) {
  strsplit(x[length(x)], split = "\\.")[[1]][1]
})


# import mutation frequency data
maps <- sapply(mfiles, function(f) {
  mapped <- read.csv(f, stringsAsFactors = FALSE)
  mapped$type <- substr(mapped$label, 1, 1)
  mapped$pos <- mapped$position+1
  mapped$alt <- sapply(strsplit(mapped$label, as.character(mapped$pos)), 
                       function(x) {
                         gsub("^\\.", "", x[2])
                       })
  # convert to omicron label type
  mapped$key <- paste(mapped$type, mapped$pos, mapped$alt, sep='|')
  
  index <- match(mutlist$key, mapped$key)
  mapped$frequency[index]
})
row.names(maps) <- mutlist$label
maps <- as.data.frame(maps)

# set column names to sample identifiers
names(maps) <- sapply(strsplit(colnames(maps), split = "/"), function(x) {
  strsplit(x[length(x)], split = "\\.")[[1]][1]
})


# set zeroes for sites with non-zero coverage
# FIXME: this is not very elegant
mask <- (cvr > 0)
for (i in 1:nrow(maps)) {
  for (j in 1:ncol(maps)) {
    if (is.na(maps[i,j]) & mask[i,j]) { maps[i,j] <- 0 }
  }
}

# convert to integer counts
counts <- as.data.frame(t(maps*cvr))
row.names(counts) <- NULL
names(counts) <- mutlist$label
row.names(counts) <- names(maps)

cvr <- as.data.frame(t(cvr))
names(cvr) <- mutlist$label

# parse metadata, dealing with varying header labels and date formats
metadata <- data.frame(sample=names(maps))
metadata$lab <- sapply(cfiles, function(x) {
  tokens <- strsplit(x, "/")[[1]]
  tokens[length(tokens)-2]
})
metadata$coldate <- rep(NA, times=nrow(counts))
metadata$site <- rep(NA, times=nrow(counts))

if (!is.na(metafile)) {
  meta <- read.csv(metafile)
  #idx <- match(counts$sample, meta[,which(grepl("sample\\.ID", names(meta)))])
  r1.fn <- meta[,which(grepl("[Rr]1\\.fastq\\.filename", names(meta)))]
  idx <- match(metadata$sample, sapply(r1.fn, function(x) {
    strsplit(as.character(x), "_")[[1]][1]
  }))
  
  # parse sample collection dates
  date.col <- which(grepl("collection\\.date", names(meta)))
  if (is.na(date.col)) {
    warning("Failed to locate sample collection date column.")
  } else {
    date.str <- meta[idx, date.col]
    metadata$coldate <- as.Date(parse_date_time(date.str, c("mdy", "dmy", "ymd")))
  }
  
  # parse sampling location
  loc.col <- which(grepl("location.name", names(meta)))
  if (is.na(loc.col)) {
    warning("Failed to locate sampling location in metadata")
  } else {
    metadata$site <- meta[idx, loc.col]
  }
}


# sort by site and collection date
idx <- order(metadata$site, metadata$coldate, metadata$sample, decreasing=T)
metadata <- metadata[idx, ]
counts <- counts[idx, ]
cvr <- cvr[idx, ]


# estimate variant frequencies
probs <- rep(NA, nrow(counts))
lo <- rep(NA, nrow(counts))
hi <- rep(NA, nrow(counts))
for (i in 1:nrow(counts)) {
  y <- as.integer(counts[i, 1:ncol(cvr)])  # number of "successes"
  n <- as.integer(cvr[i, ])  # number of trials
  # Avoid bars that will have huge error bars
  if(sum(y, na.rm = TRUE) < 3) {
    next
  }
  probs[i] <- tryCatch({
    fit <- glm(cbind(y, n-y) ~ 1, family='quasibinomial')
    exp(fit$coef) / (1+exp(fit$coef))  # probability
    }, 
    error = function(cond) { return (NA) }
    )
  
  if (sum(is.na(y)) < length(y)-1 & !is.na(probs[i]) & probs[i] >= 1e-5) { # p<1e-5 means confidence intervals fail
    suppressMessages(ci <- tryCatch(confint(fit)))
    lo[i] <- exp(ci[1]) / (1+exp(ci[1]))
    hi[i] <- exp(ci[2]) / (1+exp(ci[2]))
  }
}
estimate <- data.frame(est=probs, lower.95=lo, upper.95=hi)
row.names(estimate) <- row.names(counts)

# write output JSON
output <- list(counts=counts, coverage=cvr, metadata=metadata,
               estimate=estimate, lineage=lineage, run.dir=run.dir)
jsonlite::write_json(output, outfile, pretty=TRUE)

