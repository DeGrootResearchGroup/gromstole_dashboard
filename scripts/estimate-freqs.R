#' The purpose of this script is to fit a (quasi)binomial model to 
#' the observed frequencies of mutations that are previously determined
#' to be characteristic of a specific lineage of SARS-CoV-2.  It is meant 
#' to be run on a set of CSV outputs generated by minimap2.py

# parse command line arguments
args <- commandArgs(trailingOnly = TRUE)
if (length(args) < 3) {
  stop("\n\nUsage: Rscript estfreq.R [input dir] [lineage CSV] ",
       "[output JSON] (metadata)\n",
       "  input dir:  run folder of CSV files generated by minimap2.py\n",
       "  constellation JSON:  path to JSON with constellation\n",
       "  output JSON:  path to write JSON of frequency estimates\n",
       "  metadata:  optional, path to metadata CSV file\n\n")
}
run.dir <- args[1]  # location of CSV outputs from minimap2.py
stelfile <- args[2]
outfile <- args[3]
metafile <- NA
if (length(args) > 3) {
  metafile <- args[4]
}


#' re.findall
#'
#' Emulate behaviour of Python's re.findall() function
#'
#' @param pat:  regex pattern
#' @param s:  character, a single string
#' @return character, vector of all matching substrings
re.findall <- function(pat, s) {
  if (!is.character(s)) {
    stop("re.findall() requires a character object for input 's'")
  }
  matches <- gregexpr(pat, s)
  index <- as.integer(matches[[1]])
  match.length <- attr(matches[[1]], 'match.length')
  
  sapply(1:length(index), function(i) {
    start <- index[i]
    stop <- start + match.length[i] - 1
    substr(s, start, stop)
  })
}

# coordinates of reading frames in reference
orfs <- list(
  'orf1a'= c(265, 13468),
  'orf1b'= c(13467, 21555),
  'S'= c(21562, 25384),
  'orf3a'= c(25392, 26220),
  'E'= c(26244, 26472),
  'M'= c(26522, 27191),
  'orf6'= c(27201, 27387),
  'orf7a'= c(27393, 27759),
  'orf7b'= c(27755, 27887),
  'orf8'= c(27893, 28259),
  'N'= c(28273, 29533),
  'orf10'= c(29557, 29674),
  'nsp2' = c(806, 2719),
  'nsp3' = c(2720, 8554),
  'nsp4' = c(8555, 10054),
  'nsp5' = c(10055, 10972),
  'nsp6' = c(10973, 11842),
  'nsp12' = c(13442, 16236),
  'nsp13' = c(16237, 18039),
  'nsp15' = c(19621, 20658)
)


require(lubridate)
require(jsonlite)
require(seqinr)

refseq <- read.fasta("data/NC_045512.fa")[[1]]

# load the lineage definition (mutation list)
lineage <- gsub("^c|\\.json$", "", basename(stelfile))

if (lineage[1] == "BA.2") {
  lineage[1] <- "BA.2/BA.4/BA.5"
}

constellation <- jsonlite::read_json(stelfile, simplifyVector = TRUE)
constellation$sites <- unique(constellation$sites)

# Calculate the length of orf1a to determine if a mutation is in orf1a or orf1b
len_1a <- (orfs[['orf1a']][2]-orfs[['orf1a']][1])/3 + 1

# convert constellation to label notation in the mapped files
sites <- lapply(unique(constellation$sites), function(d) {
  toks <- toupper(strsplit(d, ":")[[1]])

  if (toks[1] != "DEL" && toks[1] != "NUC")
    toks <- c("aa", toks)
  
  if (toks[2] == "S" || toks[2] == "SPIKE") {
    toks[[2]] <- "S"
  } else if (toks[1] == "DEL") {
    toks[[1]] <- "del"
  } else if (toks[1] == "NUC") {
    toks <- toks[-1]
    toks[[1]] <- substring(toks[1], 1, nchar(toks[1]))
  } else if (toks[2] == "8") {
    toks[[2]] <- "orf8"
  } else if (toks[2] == "ORF1AB" || toks[2] == "1AB") {
    num <- as.numeric(re.findall("\\d+", toks[3]))
    if (num <= len_1a) {
      toks[[2]] <- "orf1a"
    } else {
      # Determine nucleotide position relative to the start of orf1b
      new_pos <- (((num-1) * 3 + orfs[['orf1a']][1]) - orfs[['orf1b']][1])/3
      toks[[3]] <- gsub(num, floor(new_pos) + 1, toks[[3]])
      toks[[2]] <- "orf1b"
    }
  } else if (nchar(toks[2]) >= 3 && substring(toks[2], 1, 3) == "ORF") {
    toks[[2]] <- tolower(toks[2])
  } else if (substring(toks[2], 1, 3) == "NSP") {
    start_pos <- orfs[[tolower(toks[2])]][1]
    codon <- as.integer(re.findall("\\d+", toks[3]))
    nuc_pos <- start_pos + (codon-1)*3
    if (nuc_pos >= orfs[['orf1a']][1] && nuc_pos <= orfs[['orf1a']][2]) {
      toks[[2]] <- 'orf1a'
    }
    else if (nuc_pos >= orfs[['orf1b']][1] && nuc_pos <= orfs[['orf1b']][2]) {
      toks[[2]] <- 'orf1b'
    }
    else {
      stop("Could not convert nsp to orf1a/b")
    }
    new_pos <- ((nuc_pos - orfs[[toks[2]]][1])/3) + 1
    toks[[3]] <- gsub(codon, floor(new_pos), toks[[3]])
  }
  
  if (grepl("+", toks[1], fixed = TRUE)) {
    ins <- strsplit(toks[[1]], split = "[+]")[[1]]
    toks[[1]] <- gsub(" ", "", paste("+", ins[1], ".", ins[2]))
  }
  toks <- paste(toks, collapse = ":")
})

sites <- unlist(sites, recursive = FALSE)


# locate data files
require(here)
mfiles <- list.files(here(run.dir), full.names = TRUE,
                     pattern=".+\\.mapped\\.csv$")
mfiles <- mfiles[!grepl("Undetermined", basename(mfiles))]
cfiles <- list.files(here(run.dir), full.names = TRUE,
                     pattern=".+\\.coverage\\.csv$")  
cfiles <- cfiles[!grepl("Undetermined", basename(cfiles))]

if(length(mfiles) == 0) 
  stop("No *.mapped.csv files found!")
if(length(cfiles) == 0) 
  stop("No *.coverage.csv files found!")
if(length(mfiles) != length(cfiles)) 
  stop("Mismatch between number of *.mapped.csv and *.coverage.csv files")


# import mutation frequency data
maps <- lapply(mfiles, function(f) {
  pos <- rep(NA, length(sites))
  names(pos) <- sites
  
  mapped <- read.csv(f, stringsAsFactors = FALSE)
  mapped$type <- substr(mapped$label, 1, 1)
  mapped$pos <- mapped$position+1
  mapped$alt <- sapply(strsplit(mapped$label, as.character(mapped$pos)), 
                       function(x) {
                         gsub("^\\.", "", x[2])
                       })
  
  mapped$label <- gsub("^~", "", mapped$label)
  index_label <- match(sites, mapped$label)
  
  # retrieve reference nucleotides for synonymous substitutions (nuc:)
  mapped$mutation[mapped$mutation=='None'] <- 
    paste(toupper(refseq[mapped$pos[mapped$mutation=='None']]), 
          mapped$label[mapped$mutation=='None'], sep='')
  index <- match(sites, mapped$mutation)
  
  for (i in 1:length(index)) {
    if (!is.na(index_label[i])) {
      index[[i]] <- index_label[[i]]
    }
    if (!is.na(index[[i]]) && is.na(pos[[i]])) {
      pos[i] <- mapped$pos[index[i]]
    }
  }
  list(counts=mapped$frequency[index], 
       coverage=mapped$coverage[index],
       pos=pos)
})

counts <- as.data.frame(sapply(maps, function(x) x$counts))
row.names(counts) <- sites

sample.id <- sapply(strsplit(mfiles, split = "/"), function(x) {
  strsplit(x[length(x)], split = "\\.")[[1]][1]
})
names(counts) <- sample.id

cvr <- as.data.frame(sapply(maps, function(x) x$coverage))
row.names(cvr) <- sites
names(cvr) <- sample.id

# determine nucleotide position of constellation mutations 
positions <- as.data.frame(sapply(maps, function(x) x$pos))
if (all(is.na(positions))) {
  pos <- rep(NA, length(sites))
} else {
  pos <- as.integer(apply(positions, 1, function(r) {
    tab <- table(r)
    as.integer(names(tab)[which.max(tab)])
  }))  
}


# handle missing positions (mutation never observed)
for (i in which(is.na(pos))) {
  # guess from mutation annotation
  toks <- strsplit(sites[i], ":")[[1]]
  if (length(toks) == 1) {
    # nucleotide substitution, parse position directly
    num <- re.findall("\\d+", toks[1])
    pos[i] <- as.integer(num)
  } 
  else if (toks[1] == "del") {
    # deletion annotation also contains position
    pos[i] <- as.integer(toks[2])
  }
  else {
    # use first codon position for AA substitution
    # TODO: Error handling
    start_pos <- orfs[[toks[2]]][1]  # look up ref coord
    codon <- as.integer(re.findall("\\d+", toks[3]))
    pos[i] <- start_pos + (codon-1)*3
  }
}


# import coverage data to supplement missing coverage
cvr2 <- sapply(cfiles, function(f) {
  coverage <- read.csv(f, stringsAsFactors = FALSE)
  # NOTE: coverage$position is 0-index, pos is 1-index
  idx <- match(pos, coverage$position+1)
  coverage$coverage[idx]
})
cvr2 <- as.data.frame(cvr2)
row.names(cvr2) <- sites
names(cvr2) <- sample.id


if (any(dim(cvr) != dim(cvr2))) stop("Mismatch in coverage matrices")
for (i in 1:nrow(cvr)) {
  for (j in 1:ncol(cvr)) {
    if (is.na(cvr[i,j])) {
      # fill in missing values from coverage files
      cvr[i,j] <- cvr2[i,j]
    }
    if (cvr[i,j] > 0 & is.na(counts[i,j])) {
      # set missing counts to zero if coverage exists
      counts[i,j] <- 0
    }
  }
}

# convert to integer counts and transpose so mutations are columns
counts <- as.data.frame(t(counts*cvr))
cvr <- as.data.frame(t(cvr))


# parse metadata, dealing with varying header labels and date formats
metadata <- data.frame(sample=sample.id)
metadata$lab <- sapply(cfiles, function(x) {
  tokens <- strsplit(x, "/")[[1]]
  tokens[length(tokens)-2]
})
metadata$coldate <- rep(NA, times=nrow(counts))
metadata$site <- rep(NA, times=nrow(counts))

if (!is.na(metafile)) {
  meta <- read.csv(metafile)
  #idx <- match(counts$sample, meta[,which(grepl("sample\\.ID", names(meta)))])
  r1.fn <- meta[,which(grepl("[Rr]1\\.fastq\\.filename", names(meta)))]
  idx <- match(metadata$sample, sapply(r1.fn, function(x) {
    strsplit(as.character(x), "_")[[1]][1]
  }))
  
  # parse sample collection dates
  date.col <- which(grepl("collection\\.date", names(meta)))
  if (is.na(date.col)) {
    warning("Failed to locate sample collection date column.")
  } else {
    date.str <- meta[idx, date.col]
    metadata$coldate <- as.Date(parse_date_time(date.str, c("mdy", "dmy", "ymd")))
  }
  
  # parse sampling location
  loc.col <- which(grepl("location.name", names(meta)))
  if (is.na(loc.col)) {
    warning("Failed to locate sampling location in metadata")
  } else {
    metadata$site <- meta[idx, loc.col]
  }
}


# sort by site and collection date
idx <- order(metadata$site, metadata$coldate, metadata$sample, decreasing=T)
metadata <- metadata[idx, ]
counts <- counts[idx, ]
cvr <- cvr[idx, ]


# estimate variant frequencies
probs <- rep(NA, nrow(counts))
lo <- rep(NA, nrow(counts))
hi <- rep(NA, nrow(counts))
for (i in 1:nrow(counts)) {
  y <- as.integer(counts[i, 1:ncol(cvr)])  # number of "successes"
  n <- as.integer(cvr[i, ])  # number of trials
  if(sum(!is.na(y)) == 0) {
    next  # should not try to fit a model to at least one data point
  }
  probs[i] <- tryCatch({
    fit <- glm(cbind(y, n-y) ~ 1, family='quasibinomial')
    exp(fit$coef) / (1+exp(fit$coef))  # probability
    }, 
    error = function(cond) { return (NA) }
    )
  if (sum(is.na(y)) < length(y)-1 & 
      !is.na(probs[i]) & 
      (probs[i] >= 1e-5 & probs[i] <= 1-(1e-5)) ) {
    suppressMessages(ci <- tryCatch(confint(fit)))
    lo[i] <- exp(ci[1]) / (1+exp(ci[1]))
    hi[i] <- exp(ci[2]) / (1+exp(ci[2]))
  }
  
  # handle edge case where coef > 100
  if (is.nan(probs[i])) {
    boots <- sapply(1:1000, function(i) {
      idx <- sample(1:length(y), length(y), replace=T)
      fit1 <- glm(cbind(y[idx], n[idx]-y[idx]) ~ 1, family='quasibinomial')
      bp <- fit1$coefficients[1]
      ifelse(bp > 100, 1, exp(bp)/(1+exp(bp)))
    })
    probs[i] <- mean(boots, na.rm=T)
    lo[i] <- quantile(boots, 0.025)
    hi[i] <- quantile(boots, 0.975)
  }
}
estimate <- data.frame(est=probs, lower.95=lo, upper.95=hi)
row.names(estimate) <- row.names(counts)

# write output JSON
output <- list(counts=counts, coverage=cvr, metadata=metadata,
               estimate=estimate, lineage=lineage, run.dir=run.dir)
jsonlite::write_json(output, outfile, pretty=TRUE)

