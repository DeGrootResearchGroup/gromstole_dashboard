# Wastewater Surveillance for SARS-CoV-2 Variants of Concern

## Data Format and Processing

We currently receive paired-end FASTQ files generated by the Illumina NGS platform. Each read in these files represents a qRT-PCR read based on the Artic V3 amplicons. 

We process these files by aligning them with the Wuhan-1 genome sequence, determining the mutations relative to this reference, and outputting the list of mutations along with their frequency. The frequency is determined as the number of times that mutation was observed divided by the coverage. The coverage is found by counting the number of reads that have read a base at each position. The coverage at every position (relative to the reference) are also outputted.

To determine VOCs, we need the mutations for that VOC (including how often it was observed in sequences for that variant) as well as the background frequency of the mutations.

- The mutations for a VOC can be found either by processing all sequences in the GISAID database labelled as the VOC or by using the constellation available in the Pangolin naming system.
- The background frequency is found using a pipeline that takes all GISAID sequences, determines their mutations, then counts the number of each mutation lineage divided by the number of times that mutation was observed.

## Methods

Our current modelling strategy consists of a binomial GLM for the count and coverage of the mutations that define a VOC. The VOC-defining mutations are chosen such that they are present in more than 95% of the sequences with that VOC label but fewer than 5% of the remaining data.

The model outputs an estimated proportion of a variant with the given mutations and coverage, along with an estimate of the uncertainty. A hypothesis test for the presence of the VOC can be performed by testing whether 0.01 is in the 95% confidence interval for the estimated proportion. The null 0.01 is used as this is a conservative rule-of-thumb for the sequencing error rates of the Illumina sequencing platform (these platforms also output their own estimated error rate, and incorporating this into the analysis is part of our future work).

## Detecting Relative Frequency VoC's

We have a detailed, fool-proof plan to detect the exact number of Variants of Concern that exist in the relevant population, along with the spatio-temporal spread of these variants, all while accurately determining the actual case counts of Covid-19.
This plan is as follows:

**TODO.**


## Using this repository.

The basic workflow for a given VOC is as follows:

- Gather the background frequencies of all mutations.
    - Currently, our pipeline relies on a list of mutations by lineage that is used as part of CoVizu, labelled `recoded.json`.
    - `recoded.json` is processed by `data/count-mutations.py` and outputs `count-mutations.json` which is a list of all mutations in the GISAID data along with their counts.
    - `count-mutations.json` can be used to derive the background frequency of the mutations, e.g. `get-ba1ba2-uniques.py` for B.1.1.529 and it's sublineages.
- Gather the mutations that define the variant of concern.
    - A reasonable, automated process is still an ongoing area of work.
- Gather the mutations and coverage from the wastewater sample. Our script `autoprocess.py` is designed to run on the server where our partners deposit their data, and outputs `*mapped.csv` and `*coverage.csv` files which are used in the pipeline.
    - The VOC-defining mutations are used to subset these two files and then the GLM is fit. Currently, this is done in `scripts/ba1ba2.R`, which only focuses on the most recent samples we were asked to look at. We are actively working on generalizing this script.



